{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from numbers import Number, Integral\n",
    "from typing import Optional, Union, List, Tuple\n",
    "\n",
    "ArrayOnCPU = np.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_positive_value(scalar : Number, name : str) -> Number:\n",
    "    if scalar <= 0:\n",
    "        raise ValueError(f'The parameter \\'{name}\\' should have a positive value.')\n",
    "    return scalar\n",
    "\n",
    "def matrix_mult(X : ArrayOnCPU, Y : Optional[ArrayOnCPU] = None, transpose_X : bool = False, transpose_Y : bool = False) -> ArrayOnCPU:\n",
    "    subscript_X = '...ji' if transpose_X else '...ij'\n",
    "    subscript_Y = '...kj' if transpose_Y else '...jk'\n",
    "    return np.einsum(f'{subscript_X},{subscript_Y}->...ik', X, Y if Y is not None else X)\n",
    "\n",
    "def squared_norm(X : ArrayOnCPU, axis : int = -1) -> ArrayOnCPU:\n",
    "    return np.sum(np.square(X), axis=axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class Kernel(BaseEstimator, metaclass=ABCMeta):\n",
    "    \"\"\"Base class for Kernels.\n",
    "\n",
    "    Warning: This class should not be used directly.\n",
    "    Use derived classes instead.\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, X : ArrayOnCPU, y : Optional[ArrayOnCPU] = None):\n",
    "        return self\n",
    "\n",
    "    @abstractmethod\n",
    "    def _K(self, X : ArrayOnCPU, Y : Optional[ArrayOnCPU] = None) -> ArrayOnCPU:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def _Kdiag(self, X : ArrayOnCPU) -> ArrayOnCPU:\n",
    "        pass\n",
    "\n",
    "    def __call__(self, X : ArrayOnCPU, Y : Optional[ArrayOnCPU] = None, diag : bool = False, return_on_gpu : bool = False) -> ArrayOnCPU:\n",
    "        if diag:\n",
    "            K = self._Kdiag(X)\n",
    "        else:\n",
    "            K =  self._K(X, Y)\n",
    "        return K\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "class LinearKernel(Kernel):\n",
    "    \"\"\"Class for linear (static) kernel.\"\"\"\n",
    "\n",
    "    def __init__(self, sigma : float = 1.0) -> None:\n",
    "        self.sigma = check_positive_value(sigma, 'sigma')\n",
    "\n",
    "    def _K(self, X : ArrayOnCPU, Y : Optional[ArrayOnCPU] = None) -> ArrayOnCPU:\n",
    "        return self.sigma**2 * matrix_mult(X, Y, transpose_Y=True)\n",
    "\n",
    "    def _Kdiag(self, X : ArrayOnCPU) -> ArrayOnCPU:\n",
    "        return self.sigma**2 * squared_norm(X, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_cumsum(M : ArrayOnCPU, exclusive : bool = False, axis : int = -1) -> ArrayOnCPU:\n",
    "    \"\"\"Computes the exclusive cumulative sum along a given set of axes.\n",
    "\n",
    "    Args:\n",
    "        K (np.ndarray): A matrix over which to compute the cumulative sum\n",
    "        axis (int or iterable, optional): An axis or a collection of them. Defaults to -1 (the last axis).\n",
    "    \"\"\"\n",
    "\n",
    "    ndim = M.ndim\n",
    "    axis = [axis] if np.isscalar(axis) else axis\n",
    "    axis = [ndim+ax if ax < 0 else ax for ax in axis]\n",
    "\n",
    "    # create slice for exclusive cumsum (slice off last element along given axis then pre-pad with zeros)\n",
    "    if exclusive:\n",
    "        slices = tuple(slice(-1) if ax in axis else slice(None) for ax in range(ndim))\n",
    "        M = M[slices]\n",
    "\n",
    "    # compute actual cumsums\n",
    "    for ax in axis:\n",
    "        M = np.cumsum(M, axis=ax)\n",
    "\n",
    "    # pre-pad with zeros along the given axis if exclusive cumsum\n",
    "    if exclusive:\n",
    "        pads = tuple((1, 0) if ax in axis else (0, 0) for ax in range(ndim))\n",
    "        M = np.pad(M, pads)\n",
    "\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signature_kern_higher_order(M : ArrayOnCPU, n_levels : int, order : int, difference : bool = True, return_levels : bool = False) -> ArrayOnCPU:\n",
    "    \"\"\"\n",
    "    Computes the signature kernel matrix with higher-order embedding into the tensor algebra.\n",
    "    \"\"\"\n",
    "\n",
    "    if difference:\n",
    "        M = np.diff(np.diff(M, axis=1), axis=-1)\n",
    "\n",
    "    if M.ndim == 4:\n",
    "        n_X, n_Y = M.shape[0], M.shape[2]\n",
    "        K = np.ones((n_X, n_Y), dtype=M.dtype)\n",
    "    else:\n",
    "        n_X = M.shape[0]\n",
    "        K = np.ones((n_X,), dtype=M.dtype)\n",
    "\n",
    "    if return_levels:\n",
    "        K = [K, np.sum(M, axis=(1, -1))]\n",
    "    else:\n",
    "        K += np.sum(M, axis=(1, -1))\n",
    "\n",
    "    R = np.copy(M)[None, None, ...]\n",
    "    for i in range(1, n_levels):\n",
    "        d = min(i+1, order)\n",
    "        R_next = np.empty((d, d) + M.shape, dtype=M.dtype)\n",
    "        R_next[0, 0] = M * multi_cumsum(np.sum(R, axis=(0, 1)), exclusive=True, axis=(1, -1))\n",
    "        for r in range(1, d):\n",
    "            R_next[0, r] = 1./(r+1) * M * multi_cumsum(np.sum(R[:, r-1], axis=0), exclusive=True, axis=1)\n",
    "            R_next[r, 0] = 1./(r+1) * M * multi_cumsum(np.sum(R[r-1, :], axis=0), exclusive=True, axis=-1)\n",
    "            for s in range(1, d):\n",
    "                R_next[r, s] = 1./((r+1)*(s+1)) * M * R[r-1, s-1]\n",
    "        R = R_next\n",
    "        if return_levels:\n",
    "            K.append(np.sum(R, axis=(0, 1, 3, -1)))\n",
    "        else:\n",
    "            K += np.sum(R, axis=(0, 1, 3, -1))\n",
    "\n",
    "    return np.stack(K, axis=0) if return_levels else K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 50, 1), (4, 50, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simulate geometric Brownian motion paths\n",
    "n_paths = 4\n",
    "n_steps = 50 - 1\n",
    "\n",
    "mu_x = 0.1\n",
    "sigma_x = 0.2\n",
    "mu_y = 0.2\n",
    "sigma_y = 0.2\n",
    "dt = 0.01\n",
    "X = np.exp((mu_x - 0.5 * sigma_x**2) * dt + sigma_x * np.sqrt(dt) * np.random.randn(n_paths, n_steps))\n",
    "Y = np.exp((mu_y - 0.5 * sigma_y**2) * dt + sigma_y * np.sqrt(dt) * np.random.randn(n_paths, n_steps))\n",
    "X = np.cumprod(X, axis=1)\n",
    "Y = np.cumprod(Y, axis=1)\n",
    "X = np.concatenate([np.ones((n_paths, 1)), X], axis=1)\n",
    "Y = np.concatenate([np.ones((n_paths, 1)), Y], axis=1)\n",
    "X = X[..., np.newaxis]\n",
    "Y = Y[..., np.newaxis]\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 50, 4, 50), (4, 50, 4, 50), (4, 50, 4, 50))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_kernel = LinearKernel()\n",
    "\n",
    "# M = static_kernel(X, diag=True, return_on_gpu=True)\n",
    "\n",
    "M_X = static_kernel(X.reshape((-1, X.shape[-1])), return_on_gpu=True).reshape((X.shape[0], X.shape[1], X.shape[0], X.shape[1]))\n",
    "M_Y = static_kernel(Y.reshape((-1, Y.shape[-1])), return_on_gpu=True).reshape((Y.shape[0], Y.shape[1], Y.shape[0], Y.shape[1]))\n",
    "M_XY = static_kernel(X.reshape((-1, X.shape[-1])), Y.reshape((-1, Y.shape[-1])), return_on_gpu=True).reshape((X.shape[0], X.shape[1], Y.shape[0], Y.shape[1]))\n",
    "M_X.shape, M_Y.shape, M_XY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6, 4, 4), (4, 4))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_levels = 5\n",
    "order = 5\n",
    "sig_levels = signature_kern_higher_order(M_XY, n_levels, order, return_levels=True)\n",
    "sig = signature_kern_higher_order(M_XY, n_levels, order, return_levels=False)\n",
    "sig_levels.shape, sig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_symmetric(X):\n",
    "    if X.ndim == 2:\n",
    "        return np.allclose(X, X.T)\n",
    "    else:\n",
    "        raise ValueError('X must be a 2D matrix')\n",
    "\n",
    "is_symmetric(sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94603477, 0.98041265, 0.91455012, 1.00187657],\n",
       "       [1.01778198, 1.00637977, 1.02846249, 0.99939313],\n",
       "       [1.06701221, 1.02385792, 1.10803374, 0.99774129],\n",
       "       [0.98546588, 0.99475847, 0.97684788, 1.00050018]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 4, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norms = signature_kern_higher_order(M_Y, n_levels, order, return_levels=True)\n",
    "norms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1.]\n",
      "[0.25855752 0.09302766 0.41276635 0.00886461]\n",
      "[3.34259965e-02 4.32707289e-03 8.51880279e-02 3.92906649e-05]\n",
      "[2.88084762e-03 1.34179157e-04 1.17209170e-02 1.16098816e-07]\n",
      "[1.86216207e-04 3.12059329e-06 1.20950002e-03 2.57299626e-10]\n",
      "[9.62952024e-06 5.80602992e-08 9.98481804e-05 4.57947170e-13]\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_levels + 1):\n",
    "    print(np.sqrt(norms[i].diagonal()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(sig_levels.sum(axis=0), sig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ksig",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
