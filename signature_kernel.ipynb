{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "\n",
    "from numbers import Number, Integral\n",
    "from typing import Optional, Union, List, Tuple\n",
    "\n",
    "ArrayOnCPU = np.ndarray\n",
    "ArrayOnGPU = cp.ndarray\n",
    "ArrayOnCPUOrGPU = Union[cp.ndarray, np.ndarray]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "from sklearn.base import BaseEstimator\n",
    "from ksig import utils\n",
    "\n",
    "class Kernel(BaseEstimator, metaclass=ABCMeta):\n",
    "    \"\"\"Base class for Kernels.\n",
    "\n",
    "    Warning: This class should not be used directly.\n",
    "    Use derived classes instead.\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, X : ArrayOnCPUOrGPU, y : Optional[ArrayOnCPUOrGPU] = None):\n",
    "        return self\n",
    "\n",
    "    @abstractmethod\n",
    "    def _K(self, X : ArrayOnGPU, Y : Optional[ArrayOnGPU] = None) -> ArrayOnGPU:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def _Kdiag(self, X : ArrayOnGPU) -> ArrayOnGPU:\n",
    "        pass\n",
    "\n",
    "    def __call__(self, X : ArrayOnCPUOrGPU, Y : Optional[ArrayOnCPUOrGPU] = None, diag : bool = False, return_on_gpu : bool = False) -> ArrayOnCPUOrGPU:\n",
    "        X = cp.asarray(X)\n",
    "        Y = cp.asarray(Y) if Y is not None else None\n",
    "        if diag:\n",
    "            K = self._Kdiag(X)\n",
    "        else:\n",
    "            K =  self._K(X, Y)\n",
    "        if not return_on_gpu:\n",
    "            K = cp.asnumpy(K)\n",
    "        return K\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "class LinearKernel(Kernel):\n",
    "    \"\"\"Class for linear (static) kernel.\"\"\"\n",
    "\n",
    "    def __init__(self, sigma : float = 1.0) -> None:\n",
    "        self.sigma = utils.check_positive_value(sigma, 'sigma')\n",
    "\n",
    "    def _K(self, X : ArrayOnGPU, Y : Optional[ArrayOnGPU] = None) -> ArrayOnGPU:\n",
    "        return self.sigma**2 * utils.matrix_mult(X, Y, transpose_Y=True)\n",
    "\n",
    "    def _Kdiag(self, X : ArrayOnGPU) -> ArrayOnGPU:\n",
    "        return self.sigma**2 * utils.squared_norm(X, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_cumsum(M : ArrayOnGPU, exclusive : bool = False, axis : int = -1) -> ArrayOnGPU:\n",
    "    \"\"\"Computes the exclusive cumulative sum along a given set of axes.\n",
    "\n",
    "    Args:\n",
    "        K (cp.ndarray): A matrix over which to compute the cumulative sum\n",
    "        axis (int or iterable, optional): An axis or a collection of them. Defaults to -1 (the last axis).\n",
    "    \"\"\"\n",
    "\n",
    "    ndim = M.ndim\n",
    "    axis = [axis] if cp.isscalar(axis) else axis\n",
    "    axis = [ndim+ax if ax < 0 else ax for ax in axis]\n",
    "\n",
    "    # create slice for exclusive cumsum (slice off last element along given axis then pre-pad with zeros)\n",
    "    if exclusive:\n",
    "        slices = tuple(slice(-1) if ax in axis else slice(None) for ax in range(ndim))\n",
    "        M = M[slices]\n",
    "\n",
    "    # compute actual cumsums\n",
    "    for ax in axis:\n",
    "        M = cp.cumsum(M, axis=ax)\n",
    "\n",
    "    # pre-pad with zeros along the given axis if exclusive cumsum\n",
    "    if exclusive:\n",
    "        pads = tuple((1, 0) if ax in axis else (0, 0) for ax in range(ndim))\n",
    "        M = cp.pad(M, pads)\n",
    "\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signature_kern_higher_order(M : ArrayOnGPU, n_levels : int, order : int, difference : bool = True, return_levels : bool = False) -> ArrayOnGPU:\n",
    "    \"\"\"\n",
    "    Computes the signature kernel matrix with higher-order embedding into the tensor algebra.\n",
    "    \"\"\"\n",
    "\n",
    "    if difference:\n",
    "        M = cp.diff(cp.diff(M, axis=1), axis=-1)\n",
    "\n",
    "    if M.ndim == 4:\n",
    "        n_X, n_Y = M.shape[0], M.shape[2]\n",
    "        K = cp.ones((n_X, n_Y), dtype=M.dtype)\n",
    "    else:\n",
    "        n_X = M.shape[0]\n",
    "        K = cp.ones((n_X,), dtype=M.dtype)\n",
    "\n",
    "    if return_levels:\n",
    "        K = [K, cp.sum(M, axis=(1, -1))]\n",
    "    else:\n",
    "        K += cp.sum(M, axis=(1, -1))\n",
    "\n",
    "    R = cp.copy(M)[None, None, ...]\n",
    "    for i in range(1, n_levels):\n",
    "        d = min(i+1, order)\n",
    "        R_next = cp.empty((d, d) + M.shape, dtype=M.dtype)\n",
    "        R_next[0, 0] = M * multi_cumsum(cp.sum(R, axis=(0, 1)), exclusive=True, axis=(1, -1))\n",
    "        for r in range(1, d):\n",
    "            R_next[0, r] = 1./(r+1) * M * multi_cumsum(cp.sum(R[:, r-1], axis=0), exclusive=True, axis=1)\n",
    "            R_next[r, 0] = 1./(r+1) * M * multi_cumsum(cp.sum(R[r-1, :], axis=0), exclusive=True, axis=-1)\n",
    "            for s in range(1, d):\n",
    "                R_next[r, s] = 1./((r+1)*(s+1)) * M * R[r-1, s-1]\n",
    "        R = R_next\n",
    "        if return_levels:\n",
    "            K.append(cp.sum(R, axis=(0, 1, 3, -1)))\n",
    "        else:\n",
    "            K += cp.sum(R, axis=(0, 1, 3, -1))\n",
    "\n",
    "    return cp.stack(K, axis=0) if return_levels else K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 50, 1), (4, 50, 1))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simulate geometric Brownian motion paths\n",
    "n_paths = 4\n",
    "n_steps = 50 - 1\n",
    "\n",
    "mu_x = 0.1\n",
    "sigma_x = 0.2\n",
    "mu_y = 0.2\n",
    "sigma_y = 0.2\n",
    "dt = 0.01\n",
    "X = np.exp((mu_x - 0.5 * sigma_x**2) * dt + sigma_x * np.sqrt(dt) * np.random.randn(n_paths, n_steps))\n",
    "Y = np.exp((mu_y - 0.5 * sigma_y**2) * dt + sigma_y * np.sqrt(dt) * np.random.randn(n_paths, n_steps))\n",
    "X = np.cumprod(X, axis=1)\n",
    "Y = np.cumprod(Y, axis=1)\n",
    "X = np.concatenate([np.ones((n_paths, 1)), X], axis=1)\n",
    "Y = np.concatenate([np.ones((n_paths, 1)), Y], axis=1)\n",
    "X = X[..., np.newaxis]\n",
    "Y = Y[..., np.newaxis]\n",
    "X = cp.asarray(X)\n",
    "Y = cp.asarray(Y)\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 50, 4, 50), (4, 50, 4, 50), (4, 50, 4, 50))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_kernel = LinearKernel()\n",
    "\n",
    "# M = static_kernel(X, diag=True, return_on_gpu=True)\n",
    "\n",
    "M_X = static_kernel(X.reshape((-1, X.shape[-1])), return_on_gpu=True).reshape((X.shape[0], X.shape[1], X.shape[0], X.shape[1]))\n",
    "M_Y = static_kernel(Y.reshape((-1, Y.shape[-1])), return_on_gpu=True).reshape((Y.shape[0], Y.shape[1], Y.shape[0], Y.shape[1]))\n",
    "M_XY = static_kernel(X.reshape((-1, X.shape[-1])), Y.reshape((-1, Y.shape[-1])), return_on_gpu=True).reshape((X.shape[0], X.shape[1], Y.shape[0], Y.shape[1]))\n",
    "M_X.shape, M_Y.shape, M_XY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6, 4, 4), (4, 4))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_levels = 5\n",
    "order = 5\n",
    "sig_levels = signature_kern_higher_order(M_XY, n_levels, order, return_levels=True)\n",
    "sig = signature_kern_higher_order(M_XY, n_levels, order, return_levels=False)\n",
    "sig_levels.shape, sig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_symmetric(X):\n",
    "    if X.ndim == 2:\n",
    "        return cp.allclose(X, X.T)\n",
    "    else:\n",
    "        raise ValueError('X must be a 2D matrix')\n",
    "\n",
    "is_symmetric(sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99468976, 1.00585679, 1.00666171, 1.01360896],\n",
       "       [0.99984128, 1.00017458, 1.00019853, 1.00040489],\n",
       "       [1.00472597, 0.99481501, 0.99410465, 0.98799583],\n",
       "       [1.00436833, 0.99520649, 0.99454969, 0.98890074]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 4, 4)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norms = signature_kern_higher_order(M_Y, n_levels, order, return_levels=True)\n",
    "norms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1.]\n",
      "[0.07637501 0.084001   0.09552646 0.19481062]\n",
      "[0.00291657 0.00352808 0.00456265 0.01897559]\n",
      "[7.42510623e-05 9.87875415e-05 1.45284673e-04 1.23221546e-03]\n",
      "[1.41773149e-06 2.07456316e-06 3.46963263e-06 6.00121650e-05]\n",
      "[2.16558528e-08 3.48530776e-08 6.62883444e-08 2.33820144e-06]\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_levels + 1):\n",
    "    print(cp.sqrt(norms[i].diagonal()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.allclose(sig_levels.sum(axis=0), sig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ksig",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
